\documentclass[../tech_report_1.tex]{subfiles}
\graphicspath{{img/}{../img/}}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

\begin{document}
\section{Introduction}

% TODO: revise

In visually understanding the world around us, we have attributes such as color, texture, scale, ect. But to truly understand objects, all we fundamentally need is shape. Understanding shape is essential in understanding the world and it's meaning. Our goal is to allow computers to understand shape like humans naturally do. We want them to see through all the distortions and capture the essence of an object as an important piece of the quest to make machines more intelligent. The question of shape retrieval is: given a shape, how can we find the most similar shapes from our database? How can we understand these shapes using geometry alone, without any textual metadata or context? 

In the big picture, shape retrieval can be broken up into three stages:
shape representation, feature representation, and retrieval mechanics. The shape is given to us as 2D points, 3D points, or 3D mesh. These shapes undergo preprocessing in order to transform into a feature representation that can be used as a measureable property for clustering similar objects. For our particular implementation we used Laplace-Beltrami Operator signatures and wavelet density coefficients to map that onto the surface of a unit hypersphere. Our main work for this paper so far is retrieval mechanics.

To understand how to best cluster on the multidimensional unit hypersphere's curved manifold, we exectued an experiement with sample data plotted by the Von-Mises distribution on a 2-sphere. Then we ran a MATLAB implementation Sphereical K-means to test its accuracy on our sample data. We ran this clustering method against a method from differential geometry called the Karcher mean. Once we decided on a clustering method, we used this in hierarchical clustering to form a decision tree. We performed another experiment to decided between agglomerative and divisive hierarchical clustering. We tested its runtime, storage, and overall complexity of both approaches. We also analyzed both algorithms and found interesting results that we will expand on later in the paper.

Once we had working code to cluster on the unit hypersphere and
created a decision tree, we researched how our algorithm and retrieval list will be evaluated by the Shape Retrieval Contest (SHREC). Unfortunately, our evaluation scores for all the metrics weren't ideal. We feel this may be due to the highly condensed area of data points which the clustering fails to appropriately group.

\blfootnote{AMALTHEA REU Technical Report No. 2016â€“--5; available at \href{www.amalthea-reu.org}{www.amalthea-reu.org}. Please send your correspondence to Georgios C. Anagnostopoulos. Copyright \textcopyright \thickspace 2016 The AMALTHEA REU Program.}

\end{document}
